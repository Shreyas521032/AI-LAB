{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Write the python code to perform sentiment analysis using NLP"
      ],
      "metadata": {
        "id": "RbL5xDkajlBM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2kdvbFXjHgZ",
        "outputId": "1bca62c9-b6f1-4aa6-8272-339c6eddb19d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    \"\"\"Analyzes the sentiment of a given text.\"\"\"\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "    scores = analyzer.polarity_scores(text)\n",
        "    sentiment = \"positive\" if scores['compound'] >= 0.05 else \"negative\" if scores['compound'] <= -0.05 else \"neutral\"\n",
        "    return sentiment\n",
        "\n",
        "# Example usage\n",
        "text = \"This is a great product! I highly recommend it.\"\n",
        "sentiment = analyze_sentiment(text)\n",
        "print(f\"Sentiment: {sentiment}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the python code to detect Fake News using NLP"
      ],
      "metadata": {
        "id": "lmm1QsNvjmSz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "data = [\n",
        "    (\"This is a real news article.\", 0),\n",
        "    (\"Breaking: Aliens landed in New York City!\", 1),\n",
        "    (\"Scientists discover a cure for cancer.\", 0),\n",
        "    (\"The Earth is flat and the government is hiding it.\", 1),\n",
        "    (\"New study shows coffee is good for your health.\", 0),\n",
        "    (\"President resigns amid scandal.\", 0),\n",
        "    (\"Celebrity caught in compromising situation.\", 1),\n",
        "    (\"Local sports team wins championship.\", 0),\n",
        "    (\"Financial markets experience record highs.\", 0),\n",
        "    (\"Government announces new tax policy.\", 0),\n",
        "]\n",
        "\n",
        "texts, labels = zip(*data)\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_features = vectorizer.fit_transform(texts)\n",
        "\n",
        "model = PassiveAggressiveClassifier()\n",
        "model.fit(tfidf_features, labels)\n",
        "\n",
        "def detect_fake_news(text):\n",
        "    tfidf_features = vectorizer.transform([text])\n",
        "    prediction = model.predict(tfidf_features)[0]\n",
        "    return \"Fake\" if prediction == 1 else \"Real\"\n",
        "\n",
        "texts_to_check = [\n",
        "    \"The Earth is flat.\",\n",
        "    \"Scientists have made a breakthrough in renewable energy.\",\n",
        "    \"The moon is made of cheese.\",\n",
        "    \"A new vaccine for COVID-19 is available.\",\n",
        "]\n",
        "\n",
        "for text in texts_to_check:\n",
        "    fake_news_status = detect_fake_news(text)\n",
        "    print(f\"Text: {text}\\nFake News Status: {fake_news_status}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0aONO3KjqSd",
        "outputId": "9d879f10-0def-42d4-e2e3-720f55359582"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: The Earth is flat.\n",
            "Fake News Status: Fake\n",
            "\n",
            "Text: Scientists have made a breakthrough in renewable energy.\n",
            "Fake News Status: Fake\n",
            "\n",
            "Text: The moon is made of cheese.\n",
            "Fake News Status: Fake\n",
            "\n",
            "Text: A new vaccine for COVID-19 is available.\n",
            "Fake News Status: Real\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    }
  ]
}